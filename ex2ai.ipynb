{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name:Aditi Nyamagoud\n",
        "\n",
        "Class: B.Tech\n",
        "\n",
        "Div: B (B2)\n",
        "\n",
        "PRN:22SC114501095\n",
        "\n",
        "\n",
        "Title:Impact of Data Quality on AI fairness"
      ],
      "metadata": {
        "id": "WdKe9qnAhhoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fairlearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KA7jDzHhAnXT",
        "outputId": "20445fbe-1448-47d9-a5d4-efd92ad31e70"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fairlearn\n",
            "  Downloading fairlearn-0.12.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.16.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.17.0)\n",
            "Downloading fairlearn-0.12.0-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fairlearn\n",
            "Successfully installed fairlearn-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from fairlearn.metrics import MetricFrame, true_positive_rate, false_positive_rate"
      ],
      "metadata": {
        "id": "8UUHQsEnAZzi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Load & Inspect Data**"
      ],
      "metadata": {
        "id": "h1vzS6lC_5lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('employee.1.csv')"
      ],
      "metadata": {
        "id": "usn-ETVnAM8h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7gQsUXtuA16Z",
        "outputId": "79cc555b-fe3b-41fa-903c-1fb34b259353"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Education', 'JoiningYear', 'City', 'PaymentTier', 'Age', 'Gender',\n",
              "       'EverBenched', 'ExperienceInCurrentDomain', 'LeaveOrNot'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the categorical column\n",
        "df = pd.get_dummies(df, columns=['Education', 'City', 'Gender', 'EverBenched', 'PaymentTier'], drop_first=True)\n"
      ],
      "metadata": {
        "id": "KurCRgJZCA1z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "features = ['Age', 'ExperienceInCurrentDomain']\n",
        "features += [col for col in df.columns if col.startswith(('Education_', 'City_', 'Gender_', 'EverBenched_', 'PaymentTier_'))]\n",
        "X = df[features]\n",
        "y = df['LeaveOrNot'].astype(int)\n",
        "race = df['Gender_M'] if 'Gender_M' in df.columns else df.filter(like='Gender_').iloc[:, 0]\n",
        "\n"
      ],
      "metadata": {
        "id": "Yc1Hnf4pCDdx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test, race_train, race_test = \\\n",
        "    train_test_split(X, y, race, test_size=0.3, stratify=race)"
      ],
      "metadata": {
        "id": "hoNkru6hChFi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "d13264c5-8942-4a51-90cd-f65c5ad08c2b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'education' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1674257035.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrace_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrace_test\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meducation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'education' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "J_8i1_96ClI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fairlearn.metrics import (\n",
        "    MetricFrame,\n",
        "    true_positive_rate,\n",
        "    false_positive_rate,\n",
        "    selection_rate,\n",
        "    demographic_parity_difference,\n",
        "    equalized_odds_difference,\n",
        "    false_negative_rate,\n",
        "    true_negative_rate\n",
        ")"
      ],
      "metadata": {
        "id": "wkh87nxLPp3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_frame = MetricFrame(\n",
        "    metrics={\n",
        "        'TPR': true_positive_rate,\n",
        "        'FPR': false_positive_rate,\n",
        "        'FNR': false_negative_rate,\n",
        "        'Selection Rate': selection_rate\n",
        "    },\n",
        "    y_true=y_test,\n",
        "    y_pred=y_pred,\n",
        "    sensitive_features=race_test\n",
        ")\n",
        "\n",
        "print(\"Fairness Metrics by Race Group:\\n\", metric_frame.by_group)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJFLtCnEQvZX",
        "outputId": "50d4fe9c-1231-4225-f48e-22bf31d81488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fairness Metrics by Race Group:\n",
            "                        TPR       FPR       FNR  Selection Rate\n",
            "race                                                          \n",
            "African-American  0.681979  0.324125  0.318021        0.506763\n",
            "Caucasian         0.413681  0.179487  0.586319        0.277174\n"
          ]
        }
      ]
    }
  ]
}